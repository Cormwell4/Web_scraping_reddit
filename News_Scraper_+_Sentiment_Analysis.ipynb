{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgeQH-6byt89",
        "outputId": "47bcdde2-61e4-4b7a-f59a-a56dced3e36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install textblob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from textblob import TextBlob\n",
        "\n",
        "# NewsAPI key\n",
        "api_key = 'c7ed55456f4d44828f356288cffb68e3'\n",
        "\n",
        "# endpoint and params\n",
        "url = 'https://newsapi.org/v2/everything'\n",
        "\n",
        "query = 'avian influenza'\n",
        "page_size = 10  # max articles per request\n",
        "total_pages = 10  # max pages to fetch\n",
        "\n",
        "def sentiment_description(score):\n",
        "    if score > 0.2:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.2:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# open csv file for writing\n",
        "with open('news_articles.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # write the header row\n",
        "    writer.writerow(['Post_id', 'Source', 'Title', 'Author', 'Timestamp', 'Text', 'Post_URL', 'Title_Sentiment_Score', 'Title_Sentiment', 'Text_Sentiment_Score', 'Text_Sentiment'])\n",
        "\n",
        "    for page in range(1, total_pages + 1):\n",
        "        params = {\n",
        "            'apiKey': api_key,\n",
        "            'q': query,\n",
        "            'pageSize': page_size,\n",
        "            'page': page\n",
        "        }\n",
        "\n",
        "        # make the request\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        # check for successful response\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            articles = data['articles']\n",
        "\n",
        "            # write article data rows\n",
        "            for i, article in enumerate(articles, start=(page - 1) * page_size + 1):\n",
        "                title = article['title']\n",
        "                text = article.get('content', '')\n",
        "\n",
        "                # perform sentiment analysis\n",
        "                title_sentiment_score = TextBlob(title).sentiment.polarity\n",
        "                text_sentiment_score = TextBlob(text).sentiment.polarity if text else 0\n",
        "\n",
        "                title_sentiment = sentiment_description(title_sentiment_score)\n",
        "                text_sentiment = sentiment_description(text_sentiment_score)\n",
        "\n",
        "                writer.writerow([\n",
        "                    f'news_{i}',  # post id (generic unique identifier)\n",
        "                    article['source']['name'],  # source\n",
        "                    title,  # title\n",
        "                    article['author'] if article['author'] else 'Unknown',  # author\n",
        "                    datetime.strptime(article['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%m/%d/%Y %I:%M:%S %p %Z\"),  # timestamp\n",
        "                    text,  # text\n",
        "                    article['url'],  # post url\n",
        "                    title_sentiment_score,  # title sentiment score\n",
        "                    title_sentiment,  # title sentiment\n",
        "                    text_sentiment_score,  # text sentiment score\n",
        "                    text_sentiment  # text sentiment\n",
        "                ])\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code}\")\n",
        "            break  # stop if there's an error\n",
        "\n",
        "print('CSV file with sentiment analysis and descriptions has been created successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bauHcNlzyyWx",
        "outputId": "f57d0897-7b7d-4076-a81c-bd67018f8d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file with sentiment analysis and descriptions has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dazYUdeyzcvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}